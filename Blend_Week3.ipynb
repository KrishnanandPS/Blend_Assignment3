{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47c04976-17fb-4198-ba6b-bf806681afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 128975 rows\n",
      "+-----+-------------------+---------+--------------------+----------+--------------+------------------+-------+---------------+-------------+----+----------+--------------+---+--------+------+-----------+-----------+----------------+------------+--------------------+-----+------------+----+\n",
      "|index|           Order ID|     Date|              Status|Fulfilment|Sales Channel |ship-service-level|  Style|            SKU|     Category|Size|      ASIN|Courier Status|Qty|currency|Amount|  ship-city| ship-state|ship-postal-code|ship-country|       promotion-ids|  B2B|fulfilled-by|_c23|\n",
      "+-----+-------------------+---------+--------------------+----------+--------------+------------------+-------+---------------+-------------+----+----------+--------------+---+--------+------+-----------+-----------+----------------+------------+--------------------+-----+------------+----+\n",
      "|    0|405-8078784-5731545|4/30/2022|           Cancelled|  Merchant|     Amazon.in|          Standard| SET389| SET389-KR-NP-S|          Set|   S|B09KXVBD7Z|          NULL|  0|     INR|647.62|     MUMBAI|MAHARASHTRA|          400081|          IN|                NULL|false|   Easy Ship|NULL|\n",
      "|    1|171-9198151-1101146|4/30/2022|Shipped - Deliver...|  Merchant|     Amazon.in|          Standard|JNE3781|JNE3781-KR-XXXL|        kurta| 3XL|B09K3WFS32|       Shipped|  1|     INR| 406.0|  BENGALURU|  KARNATAKA|          560085|          IN|Amazon PLCC Free-...|false|   Easy Ship|NULL|\n",
      "|    2|404-0687676-7273146|4/30/2022|             Shipped|    Amazon|     Amazon.in|         Expedited|JNE3371|  JNE3371-KR-XL|        kurta|  XL|B07WV4JV4D|       Shipped|  1|     INR| 329.0|NAVI MUMBAI|MAHARASHTRA|          410210|          IN|IN Core Free Ship...| true|        NULL|NULL|\n",
      "|    3|403-9615377-8133951|4/30/2022|           Cancelled|  Merchant|     Amazon.in|          Standard|  J0341|     J0341-DR-L|Western Dress|   L|B099NRCT7B|          NULL|  0|     INR|753.33| PUDUCHERRY| PUDUCHERRY|          605008|          IN|                NULL|false|   Easy Ship|NULL|\n",
      "|    4|407-1069790-7240320|4/30/2022|             Shipped|    Amazon|     Amazon.in|         Expedited|JNE3671|JNE3671-TU-XXXL|          Top| 3XL|B098714BZP|       Shipped|  1|     INR| 574.0|    CHENNAI| TAMIL NADU|          600073|          IN|                NULL|false|        NULL|NULL|\n",
      "+-----+-------------------+---------+--------------------+----------+--------------+------------------+-------+---------------+-------------+----+----------+--------------+---+--------+------+-----------+-----------+----------------+------------+--------------------+-----+------------+----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"Amazon Sale Report(in).csv\", header=True, inferSchema=True)\n",
    "print(f\"Loaded {df.count()} rows\")\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1b95410-850c-40cd-b49d-6e9437da63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set Hadoop home\n",
    "os.environ['HADOOP_HOME'] = r'C:\\hadoop'\n",
    "os.environ['PATH'] += r';C:\\hadoop\\bin'\n",
    "# Restart Spark with Hadoop configured\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Sales\") \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ec2b4a7-5c12-466a-b6ef-7a30117f07d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Spark started\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Sales_ETL\") \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✓ Spark started\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9fc15e52-7f37-4516-9878-3c88fdc2b8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean rows: 68930\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.dropDuplicates(['Order ID']) \\\n",
    "    .fillna({'Amount': 0, 'Qty': 0, 'ship-state': 'Unknown'}) \\\n",
    "    .dropna(subset=['Order ID', 'Date'])\n",
    "\n",
    "print(f\"Clean rows: {df_clean.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea7345eb-76f9-481c-9e4d-0553c4f0f955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishnanand PS\\AppData\\Local\\Temp\\ipykernel_20540\\997367135.py:2: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"Amazon Sale Report(in).csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+----------+--------------------+----------+--------------+------------------+-------+---------------+-------------+----+----------+--------------+---+--------+------+-----------+-----------+----------------+------------+--------------------+-----+------------+-----------+---------+\n",
      "|index|           Order ID|      Date|              Status|Fulfilment|Sales Channel |ship-service-level|  Style|            SKU|     Category|Size|      ASIN|Courier Status|Qty|currency|Amount|  ship-city| ship-state|ship-postal-code|ship-country|       promotion-ids|  B2B|fulfilled-by|Unnamed: 23|YearMonth|\n",
      "+-----+-------------------+----------+--------------------+----------+--------------+------------------+-------+---------------+-------------+----+----------+--------------+---+--------+------+-----------+-----------+----------------+------------+--------------------+-----+------------+-----------+---------+\n",
      "|    0|405-8078784-5731545|2022-04-30|           Cancelled|  Merchant|     Amazon.in|          Standard| SET389| SET389-KR-NP-S|          Set|   S|B09KXVBD7Z|          NULL|  0|     INR|647.62|     MUMBAI|MAHARASHTRA|        400081.0|          IN|                NULL|false|   Easy Ship|       NULL|  2022-04|\n",
      "|    1|171-9198151-1101146|2022-04-30|Shipped - Deliver...|  Merchant|     Amazon.in|          Standard|JNE3781|JNE3781-KR-XXXL|        kurta| 3XL|B09K3WFS32|       Shipped|  1|     INR| 406.0|  BENGALURU|  KARNATAKA|        560085.0|          IN|Amazon PLCC Free-...|false|   Easy Ship|       NULL|  2022-04|\n",
      "|    2|404-0687676-7273146|2022-04-30|             Shipped|    Amazon|     Amazon.in|         Expedited|JNE3371|  JNE3371-KR-XL|        kurta|  XL|B07WV4JV4D|       Shipped|  1|     INR| 329.0|NAVI MUMBAI|MAHARASHTRA|        410210.0|          IN|IN Core Free Ship...| true|        NULL|       NULL|  2022-04|\n",
      "|    3|403-9615377-8133951|2022-04-30|           Cancelled|  Merchant|     Amazon.in|          Standard|  J0341|     J0341-DR-L|Western Dress|   L|B099NRCT7B|          NULL|  0|     INR|753.33| PUDUCHERRY| PUDUCHERRY|        605008.0|          IN|                NULL|false|   Easy Ship|       NULL|  2022-04|\n",
      "|    4|407-1069790-7240320|2022-04-30|             Shipped|    Amazon|     Amazon.in|         Expedited|JNE3671|JNE3671-TU-XXXL|          Top| 3XL|B098714BZP|       Shipped|  1|     INR| 574.0|    CHENNAI| TAMIL NADU|        600073.0|          IN|                NULL|false|        NULL|       NULL|  2022-04|\n",
      "+-----+-------------------+----------+--------------------+----------+--------------+------------------+-------+---------------+-------------+----+----------+--------------+---+--------+------+-----------+-----------+----------------+------------+--------------------+-----+------------+-----------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #cleaning first in pandas\n",
    "data = pd.read_csv(\"Amazon Sale Report(in).csv\")\n",
    "data['Date'] = pd.to_datetime(data['Date'], errors='coerce')  \n",
    "data['YearMonth'] = data['Date'].dt.to_period('M').astype(str)\n",
    "\n",
    "\n",
    "data.to_csv(\"Amazon_Sales_Clean.csv\", index=False)\n",
    "\n",
    "#loading in pyspark\n",
    "df = spark.read.csv(\"Amazon_Sales_Clean.csv\", header=True, inferSchema=True)  #saving to csv (imitates parquet)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f995787b-aafe-4f32-bb4f-ee63b77ab3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|YearMonth|             Revenue|\n",
      "+---------+--------------------+\n",
      "|      NaT| 3.347653045999995E7|\n",
      "|  2022-04|1.7516195560000014E7|\n",
      "|  2022-05|1.4987650069999937E7|\n",
      "|  2022-06|1.2510618359999996E7|\n",
      "|  2022-03|  101683.84999999998|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monthly_revenue = df.groupBy('YearMonth') \\\n",
    "    .agg(_sum('Amount').alias('Revenue')) \\\n",
    "    .orderBy(col('Revenue').desc())\n",
    "\n",
    "monthly_revenue.toPandas().to_csv('output/monthly_revenue.csv', index=False)\n",
    "\n",
    "monthly_revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f0ac29f0-30c9-47fb-b7a9-f946ed8f3109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TOP 10 STATES BY REVENUE---\n",
      "+--------------+------------------+------+-----------------+\n",
      "|    ship-state|           Revenue|Orders|  Avg_Order_Value|\n",
      "+--------------+------------------+------+-----------------+\n",
      "|   MAHARASHTRA| 7052615.170000002| 11776|598.8973479959241|\n",
      "|     KARNATAKA| 5621026.809999999|  9226|609.2593550834597|\n",
      "|     TELANGANA|3724120.5600000005|  6110|609.5123666121114|\n",
      "| UTTAR PRADESH|3628635.6500000022|  5698|636.8261934011938|\n",
      "|    TAMIL NADU| 3422890.340000001|  5990|571.4341135225377|\n",
      "|         DELHI|        2259015.99|  3589|629.4276929506827|\n",
      "|        KERALA|2104301.7700000005|  3588|586.4832134894093|\n",
      "|   WEST BENGAL|1881120.1199999992|  3129|601.1889165867686|\n",
      "|ANDHRA PRADESH|1699258.1999999997|  2859|594.3540398740818|\n",
      "|       HARYANA|1587312.8399999994|  2465|643.9403002028395|\n",
      "+--------------+------------------+------+-----------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "region_sales = df_clean.groupBy('ship-state') \\\n",
    "    .agg(_sum('Amount').alias('Revenue'),\n",
    "         count('Order ID').alias('Orders'),\n",
    "         avg('Amount').alias('Avg_Order_Value')) \\\n",
    "    .orderBy(col('Revenue').desc())\n",
    "\n",
    "region_sales.toPandas().to_csv('output/region_sales.csv', index=False)  #saving to csv (imitates parquet)\n",
    "\n",
    "print(\"---TOP 10 STATES BY REVENUE---\")\n",
    "region_sales.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2c28a9b6-cff5-428e-9d0c-11890e96ea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AVERAGE ORDER VALUE (OVERALL) ===\n",
      "+-----------------+--------------------+------------+\n",
      "|  Avg_Order_Value|       Total_Revenue|Total_Orders|\n",
      "+-----------------+--------------------+------------+\n",
      "|611.1611636442756|4.2127339009999916E7|       68930|\n",
      "+-----------------+--------------------+------------+\n",
      "\n",
      "\n",
      "=== AVERAGE ORDER VALUE BY CATEGORY ===\n",
      "+-------------+------------------+------+\n",
      "|     Category|   Avg_Order_Value|Orders|\n",
      "+-------------+------------------+------+\n",
      "|          Set| 780.5649311573816| 26655|\n",
      "|        Saree| 750.2346341463415|    82|\n",
      "|Western Dress| 718.4618957399102|  8920|\n",
      "| Ethnic Dress|        689.888125|   608|\n",
      "|          Top| 500.5786549509972|  5918|\n",
      "|       Blouse| 476.2117647058825|   544|\n",
      "|        kurta|428.69816947059724| 25916|\n",
      "|       Bottom| 348.9475524475524|   286|\n",
      "|      Dupatta|             305.0|     1|\n",
      "+-------------+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Overall aov\n",
    "aov_overall = df_clean.agg(\n",
    "    avg('Amount').alias('Avg_Order_Value'),\n",
    "    _sum('Amount').alias('Total_Revenue'),\n",
    "    count('Order ID').alias('Total_Orders')\n",
    ")\n",
    "\n",
    "# aov by Category\n",
    "aov_category = df_clean.groupBy('Category') \\\n",
    "    .agg(avg('Amount').alias('Avg_Order_Value'),\n",
    "         count('Order ID').alias('Orders')) \\\n",
    "    .orderBy(col('Avg_Order_Value').desc())\n",
    "\n",
    "aov_category.toPandas().to_csv('output/avg_order_value.csv', index=False)  #saving to csv (imitates parquet)\n",
    "aov_overall.toPandas().to_csv('output/avg_order_value.csv', index=False)   #saving to csv (imitates parquet)\n",
    "\n",
    "print(\"=== AVERAGE ORDER VALUE (OVERALL) ===\")\n",
    "aov_overall.show()\n",
    "print(\"\\n=== AVERAGE ORDER VALUE BY CATEGORY ===\")\n",
    "aov_category.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd168c50-d3fa-414e-bf70-4aa3759ec721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATEGORY PERFORMANCE ===\n",
      "+-------------+--------------------+------+--------------+------------------+\n",
      "|     Category|             Revenue|Orders|Total_Qty_Sold|         Avg_Price|\n",
      "+-------------+--------------------+------+--------------+------------------+\n",
      "|          Set|2.0805958240000006E7| 26655|         23941| 780.5649311573816|\n",
      "|        kurta|1.1110141759999998E7| 25916|         23236|428.69816947059724|\n",
      "|Western Dress|   6408680.109999999|  8920|          8002| 718.4618957399102|\n",
      "|          Top|  2962424.4800000014|  5918|          5509| 500.5786549509972|\n",
      "| Ethnic Dress|           419451.98|   608|           553|        689.888125|\n",
      "|       Blouse|  259059.20000000007|   544|           508| 476.2117647058825|\n",
      "|       Bottom|             99799.0|   286|           255| 348.9475524475524|\n",
      "|        Saree|  61519.240000000005|    82|            73| 750.2346341463415|\n",
      "|      Dupatta|               305.0|     1|             1|             305.0|\n",
      "+-------------+--------------------+------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_performance = df_clean.groupBy('Category') \\\n",
    "    .agg(_sum('Amount').alias('Revenue'),\n",
    "         count('Order ID').alias('Orders'),\n",
    "         _sum('Qty').alias('Total_Qty_Sold'),\n",
    "         avg('Amount').alias('Avg_Price')) \\\n",
    "    .orderBy(col('Revenue').desc())\n",
    "\n",
    "\n",
    "category_performance.toPandas().to_csv('output/category_performance.csv', index=False) #saving to csv (imitates parquet)\n",
    "print(\"=== CATEGORY PERFORMANCE ===\")\n",
    "category_performance.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
